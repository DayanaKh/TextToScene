{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fingerübung\n",
    "### Ex. 2.2\n",
    "###### load the zip file and open only .xml data without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import en_core_web_sm\n",
    "import xmltodict\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy #should be additionally installed, see 'requirements.txt'\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('training.zip')\n",
    "\n",
    "#uncomment if you want check which files are in\n",
    "'''\n",
    "for x in zf.namelist():\n",
    "    print(x)\n",
    "'''\n",
    "\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if you want to 'print' one of the .xml files to see its content\n",
    "\n",
    "'''\n",
    "file=zf.open('__MACOSX/Traning/ANC/WhereToJapan/._Asakusa.xml')\n",
    "bs = BeautifulSoup(file, 'xml')\n",
    "print(bs.prettify())\n",
    "file.close()\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "def dict_update(di, el, n):\n",
    "    '''\n",
    "    this is just for convinence to update the dictionaries\n",
    "    \n",
    "    '''\n",
    "    if el[0] not in di:\n",
    "        di.update({el[0]: n})\n",
    "    else:\n",
    "        di[el[0]]+=n\n",
    "    return di\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "file=zf.open('Traning/CP/47_N_22_E.xml')\n",
    "bs = BeautifulSoup(file, 'xml')\n",
    "print(bs.prettify())\n",
    "file.close()\n",
    "'''\n",
    "#the whole texts will be here:\n",
    "data=''\n",
    "\n",
    "#the number of entities:\n",
    "number = dict()\n",
    "\n",
    "#the number of different QsLink:\n",
    "qs_number = dict()\n",
    "\n",
    "#the prepositions in different files has differnet ids, therefore we just list the preposition for each QsLink and OLink\n",
    "list1=set()\n",
    "list2=set()\n",
    "\n",
    "#the motion verben\n",
    "motion=dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### determine how many different tags  are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in zf.namelist():\n",
    "    #we want only .xml files\n",
    "    if not name.endswith('.xml'): continue\n",
    "        \n",
    "    #we should not count twice (in '_MACOSX' and in 'Traning' )\n",
    "    if '__MACOSX/' in name: continue\n",
    "    \n",
    "    f = zf.open(name)\n",
    "    xml_document = xmltodict.parse(f)\n",
    "    f.close()\n",
    "    text_tags = xml_document['SpaceEvalTaskv1.2']['TEXT']\n",
    "    data+=text_tags \n",
    "    \n",
    "    \n",
    "    text_tags = xml_document['SpaceEvalTaskv1.2']['TAGS']\n",
    "    \n",
    "    #there are one case where QsLink Trigger is given(with id and not just ''), but there are no Spatial signals in the file. \n",
    "    #therefore need extra boolean variable, to avoid errors\n",
    "    b = 'SPATIAL_SIGNAL' in [x[0] for x in text_tags.items()]\n",
    "    for x in text_tags.items():\n",
    "        if not isinstance(x[1], list):\n",
    "            n = 1\n",
    "            \n",
    "            #count the number of different QsLinks:\n",
    "            if x[0] == 'QSLINK':\n",
    "                if x[1]['@relType'] not in qs_number:\n",
    "                    qs_number.update({x[1]['@relType']: 1})\n",
    "                else:\n",
    "                    qs_number[x[1]['@relType']] += 1\n",
    "                if b and not isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                    if text_tags['SPATIAL_SIGNAL']['@id'] == x[1]['@trigger']:\n",
    "                        list1.add(text_tags['SPATIAL_SIGNAL']['@text'])\n",
    "                if b and isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                    for z in text_tags['SPATIAL_SIGNAL']:\n",
    "                        if z['@id'] == x[1]['@trigger']:\n",
    "                            list1.add(z['@text'])\n",
    "            if x[0] == 'OLINK':\n",
    "                if b and not isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                    if text_tags['SPATIAL_SIGNAL']['@id'] == x[1]['@trigger']:\n",
    "                        list2.add(text_tags['SPATIAL_SIGNAL']['@text'])\n",
    "                if b and isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                    for z in text_tags['SPATIAL_SIGNAL']:\n",
    "                        if z['@id'] == x[1]['@trigger']:\n",
    "                            list2.add(z['@text'])\n",
    "            if x[0] == 'MOTION':\n",
    "                if x[1]['@text'] not in motion:\n",
    "                    motion.update({x[1]['@text']: 1})\n",
    "                else:\n",
    "                    motion[x[1]['@text']] += 1\n",
    "                \n",
    "        else: \n",
    "            n = len(x[1])\n",
    "            if x[0]=='QSLINK':\n",
    "                for y in x[1]:\n",
    "                    if y['@relType'] not in qs_number:\n",
    "                        qs_number.update({y['@relType']: 1})\n",
    "                    else:\n",
    "                        qs_number[y['@relType']]+=1\n",
    "                    if b and not isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                        if text_tags['SPATIAL_SIGNAL']['@id'] == y['@trigger']:\n",
    "                            list1.add(text_tags['SPATIAL_SIGNAL']['@text'])\n",
    "                    if b and isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                        for z in text_tags['SPATIAL_SIGNAL']:\n",
    "                            if z['@id'] == y['@trigger']:\n",
    "                                list1.add(z['@text'])\n",
    "            if x[0] == 'OLINK':\n",
    "                for y in x[1]:\n",
    "                    if b and not isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                        if text_tags['SPATIAL_SIGNAL']['@id'] == y['@trigger']:\n",
    "                            list2.add(text_tags['SPATIAL_SIGNAL']['@text'])\n",
    "                    if b and isinstance(text_tags['SPATIAL_SIGNAL'], list):\n",
    "                        for z in text_tags['SPATIAL_SIGNAL']:\n",
    "                            if z['@id'] == y['@trigger']:\n",
    "                                list2.add(z['@text'])   \n",
    "            if x[0] == 'MOTION':\n",
    "                for y in x[1]:\n",
    "                    if y['@text'] not in motion:\n",
    "                        motion.update({y['@text']: 1})\n",
    "                    else:\n",
    "                        motion[y['@text']] += 1\n",
    "                    \n",
    "        dict_update(number, x, n)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoS \n",
      "\n",
      "ADP                  adposition                     3006                \n",
      "INTJ                 interjection                   15                  \n",
      "PART                 particle                       491                 \n",
      "NUM                  numeral                        673                 \n",
      "DET                  determiner                     3203                \n",
      "X                    other                          30                  \n",
      "AUX                  auxiliary                      1031                \n",
      "SCONJ                subordinating conjunction      431                 \n",
      "SYM                  symbol                         28                  \n",
      "PRON                 pronoun                        1362                \n",
      "SPACE                space                          707                 \n",
      "NOUN                 noun                           5029                \n",
      "PUNCT                punctuation                    3481                \n",
      "VERB                 verb                           2722                \n",
      "CCONJ                coordinating conjunction       825                 \n",
      "PROPN                proper noun                    2083                \n",
      "ADV                  adverb                         1330                \n",
      "ADJ                  adjective                      1782                \n"
     ]
    }
   ],
   "source": [
    "texts=nlp(data)\n",
    "#tokenized text (all the texts)\n",
    "text = [t.text for t in texts]\n",
    "#PoS tags of the text\n",
    "tokens_text = [t.pos_ for t in texts]\n",
    "\n",
    "#tags = [t.tag_ for t in texts] \n",
    "\n",
    "#for simplicity:\n",
    "tokens_text = np.array(tokens_text)\n",
    "\n",
    "#set of PoS tags in the text\n",
    "tokens = set(tokens_text)\n",
    "print('PoS \\n')\n",
    "for x in tokens:\n",
    "    print(\"{: <20} {: <30} {: <20}\".format(*[x, spacy.explain(x), len(tokens_text[np.array(tokens_text==x)])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different Entities \n",
      "\n",
      "PLACE                1852                          \n",
      "PATH                 434                           \n",
      "SPATIAL_ENTITY       1417                          \n",
      "NONMOTION_EVENT      341                           \n",
      "MOTION               771                           \n",
      "SPATIAL_SIGNAL       714                           \n",
      "MOTION_SIGNAL        526                           \n",
      "MEASURE              170                           \n",
      "QSLINK               970                           \n",
      "OLINK                244                           \n",
      "MOVELINK             803                           \n",
      "MEASURELINK          93                            \n",
      "METALINK             1788                          \n",
      "CP                   17                            \n",
      "URL                  17                            \n",
      "MLINK                42                            \n"
     ]
    }
   ],
   "source": [
    "print('Number of different Entities \\n')\n",
    "for x in number:\n",
    "    print(\"{: <20} {: <30}\".format(*[x, number[x]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different QsLink types \n",
      "\n",
      "NTPP                 42                            \n",
      "IN                   586                           \n",
      "EC                   196                           \n",
      "TPP                  53                            \n",
      "EQ                   35                            \n",
      "PO                   12                            \n",
      "OUT                  3                             \n",
      "DC                   41                            \n",
      "                     2                             \n"
     ]
    }
   ],
   "source": [
    "print('Number of different QsLink types \\n')\n",
    "\n",
    "for x in qs_number:\n",
    "    print(\"{: <20} {: <30}\".format(*[x, qs_number[x]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We won't consider the multiple whitespaces to determine the length of a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences_length=[]\n",
    "for sent in texts.sents:\n",
    "    sentences_length.append(len([token for token in sent if not token.is_space]))\n",
    "\n",
    "# seaborn histogram\n",
    "sns.distplot(sentences_length, bins = int(max(sentences_length)/3), hist=True, kde=False, \n",
    "             color = 'blue',  hist_kws={'edgecolor':'black'})\n",
    "plt.xlabel(\"Sentence length\")\n",
    "plt.ylabel(\"Number of sentences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QsLinks are triggered by: \n",
      " {'on top of', 'with', 'houses', 'through', 'apart from', 'to', 'up', 'connects', 'surrounding', 'overlooking', 'where', 'covered', 'On', 'away from', 'apart', 'has', 'including', 'under', 'afar', 'in', 'filled', 'part         of', 'Down', 'packed', 'along', 'restricted', 'into', 'beside', 'inside', 'up to', 'inhabited', 'contain', 'full of', 'covering', 'coiling up', 'further', 'atop', 'outside', 'contains', 'directly beneath', 'In', 'behind', 'of', 'In front of', 'away', 'surmounted', 'stocked', 'far from', 'Everywhere', 'on', 'on top', 'for', 'Along', 'against', 'inside of', 'around', 'bordering', 'next to', 'adjacent to', 'in front of', 'packed with', 'over', 'between', 'about', 'out of', 'line', 'at', 'house', 'upon', 'after', 'surrounded', 'At', 'from', 'across'}\n",
      "\n",
      " \n",
      "\n",
      "OLinks are triggered by: \n",
      " {'above', 'beneath', 'on top of', 'surrounding', 'up', 'to the west from', 'to', 'Southeast of', 'overlooking', 'north of', 'covered', 'On', 'south of', 'north', 'down', 'in', 'to the left', 'Down', 'along', 'West of', 'beside', 'up to', 'upstream from', 'south', 'coiling up', 'west', 'to SW', 'atop', 'southwest', 'on the right', 'directly beneath', 'on your left', 'overlook', 'behind', 'alongside', 'below', 'toward', 'surmounted', 'In front of', 'of', 'Facing', 'east of', 'on', 'next door to', 'on top', 'Along', 'in front of', 'across from', 'around', 'east', 'next to', 'adjacent to', 'over', 'in the direction to', 'in that direction', 'between', 'South\\xadeast of', 'northeast', 'line', 'upon', 'backwards', 'facing', 'surrounded', 'under', 'neighboring', 'Across', 'across'}\n"
     ]
    }
   ],
   "source": [
    "print('QsLinks are triggered by: \\n', list1)\n",
    "print('\\n \\n')\n",
    "print('OLinks are triggered by: \\n', list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "five most frequent verbs:\n",
      " \n",
      "{'biked': 22}\n",
      "{'visited': 21}\n",
      "{'biking': 16}\n",
      "{'bike': 15}\n",
      "{'go': 15}\n"
     ]
    }
   ],
   "source": [
    "def getLastItem(dictionary):\n",
    "    last_keyval = dictionary.popitem()\n",
    "    return {last_keyval[0]:last_keyval[1]}\n",
    "\n",
    "print('five most frequent verbs:\\n ')\n",
    "dic={k: v for k, v in sorted(motion.items(), key=lambda item: item[1])}\n",
    "for i in range(5):\n",
    "    print(getLastItem(dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=zf.open('Traning/ANC/WhereToMadrid/Highlights_of_the_Prado_Museum.xml')\n",
    "xml1 = xmltodict.parse(file)   \n",
    "file.close()\n",
    "\n",
    "file=zf.open('Traning/RFC/Bicycles.xml')\n",
    "xml2 = xmltodict.parse(file)   \n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr(xml_document):\n",
    "    sp_en = xml_document['SpaceEvalTaskv1.2']['TAGS']['SPATIAL_ENTITY']\n",
    "    pl = xml_document['SpaceEvalTaskv1.2']['TAGS']['PLACE']\n",
    "    met = xml_document['SpaceEvalTaskv1.2']['TAGS']['METALINK']\n",
    "\n",
    "\n",
    "    l_sp=dict()\n",
    "    l_pl=dict()\n",
    "    l_m=[]\n",
    "\n",
    "    for x in sp_en:\n",
    "        l_sp.update({x['@id']:x['@text']})\n",
    "    for x in pl:\n",
    "        l_pl.update({x['@id']:x['@text']})\n",
    "    for x in met:\n",
    "        l_m.append((x['@fromID'], x['@toID']))\n",
    "    \n",
    "    nodes = [set(l_m[0])]\n",
    "\n",
    "    for x in l_m:\n",
    "        b = 0\n",
    "        for y in nodes:\n",
    "            if x[0] in y or x[1] in y:\n",
    "                y.add(x[0])\n",
    "                y.add(x[1])\n",
    "                b = 1\n",
    "                pass\n",
    "        if b == 0:\n",
    "            nodes.append(set(x))\n",
    "\n",
    "\n",
    "    for x in l_sp:\n",
    "        b = 0\n",
    "        for y in nodes:\n",
    "            if x in y:\n",
    "                b = 1\n",
    "                pass\n",
    "        if b == 0:\n",
    "            nodes.append(set([x]))\n",
    "\n",
    "    for x in l_pl:\n",
    "        b = 0\n",
    "        for y in nodes:\n",
    "            if x in y:\n",
    "                b = 1\n",
    "                pass\n",
    "        if b == 0:\n",
    "            nodes.append(set([x]))\n",
    "            \n",
    "    #all the qslinks\n",
    "    conn = []\n",
    "    for x in xml_document['SpaceEvalTaskv1.2']['TAGS']['QSLINK']:\n",
    "        conn.append((x['@fromID'], x['@toID'], x['@relType']))\n",
    "\n",
    "    qs_conn = conn[:]\n",
    "    #remove unneeded connections\n",
    "    for c in conn:\n",
    "        if (c[0] not in l_sp and c[0] not in l_pl) or (c[1] not in l_sp and c[1] not in l_pl):\n",
    "            qs_conn.remove(c)\n",
    "    qs = []\n",
    "    n = len(nodes)\n",
    "    \n",
    "    for c in qs_conn:\n",
    "        qs.append([[x for x in nodes if c[0] in x], [x for x in nodes if c[1] in x], c[2]])\n",
    "        \n",
    "    #all the olinks\n",
    "    conn2 = []\n",
    "    for x in xml_document['SpaceEvalTaskv1.2']['TAGS']['OLINK']:\n",
    "        conn2.append((x['@fromID'], x['@toID'], x['@relType']))\n",
    "\n",
    "    os_conn = conn2[:]\n",
    "    #remove unneeded connections\n",
    "    for c in conn2:\n",
    "        if (c[0] not in l_sp and c[0] not in l_pl) or (c[1] not in l_sp and c[1] not in l_pl):\n",
    "            os_conn.remove(c)\n",
    "    os = []\n",
    "    n = len(nodes)\n",
    "    for c in os_conn:\n",
    "        os.append([[x for x in nodes if c[0] in x], [x for x in nodes if c[1] in x], c[2]])\n",
    "    \n",
    "    for x in nodes:\n",
    "        b=0\n",
    "        for y in x:\n",
    "            if 'se' in y:\n",
    "                \n",
    "                b=1\n",
    "                print(l_sp[y])\n",
    "        if b==1:\n",
    "            print('\\n the Spatial Entities above correspond to the Node with number: ', nodes.index(x))\n",
    "            \n",
    "            print('_______________')\n",
    "    print('\\n\\n\\n')\n",
    "    for x in nodes:\n",
    "        b=0\n",
    "        for y in x:\n",
    "            if 'pl' in y:\n",
    "                b=1\n",
    "                print( l_pl[y])\n",
    "        if b==1:\n",
    "            print('\\n the Places above correspond to the Node with number: ', nodes.index(x))\n",
    "            \n",
    "            print('_______________')\n",
    "    print('\\n')\n",
    "    \n",
    "    print('\\nQSLINKS:\\n')\n",
    "    for x in qs:\n",
    "        print('node ', nodes.index(x[0][0]),'is connected by QSLink to ', nodes.index(x[1][0]), 'with relType', x[2])\n",
    "    \n",
    "    print('\\n \\n OLINKS:\\n')\n",
    "    for x in os:\n",
    "        print('node ', nodes.index(x[0][0]),'is connected by OLink to ', nodes.index(x[1][0]), 'with relType', x[2])\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have tried in latex with Tikz, with paint, \n",
      " with Xournal and even simply with colors in python, still i could not make it look somehow ok\n",
      " but it was awfull and with many mistakes. Therefore, here you can see a description of the graph: \n",
      " all the nodes with their types and all the connections between them\n",
      "\n",
      " Prado_museum graph: \n",
      "\n",
      "Guer­nica\n",
      "Guernica\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  1\n",
      "_______________\n",
      "you\n",
      "you\n",
      "\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  2\n",
      "_______________\n",
      "Surrender of Breda\n",
      "canvas\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  15\n",
      "_______________\n",
      "Goya\n",
      "he\n",
      "Goya\n",
      "Goya\n",
      "Goya\n",
      "Francisco de Goya\n",
      "He\n",
      "Goya\n",
      "Goya\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  16\n",
      "_______________\n",
      "black paintings\n",
      "They\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  17\n",
      "_______________\n",
      "masterpieces\n",
      "triptych\n",
      "The Garden of Earthly Delights\n",
      "it\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  18\n",
      "_______________\n",
      "The Three Graces\n",
      "paintings\n",
      "Adoration of the Magi\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  19\n",
      "_______________\n",
      "collections\n",
      "it\n",
      "one\n",
      "it\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  20\n",
      "_______________\n",
      "this\n",
      "arch\n",
      "arch\n",
      "Puerta de         Al­ca­lá\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  21\n",
      "_______________\n",
      "portraits\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  22\n",
      "_______________\n",
      "studies\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  23\n",
      "_______________\n",
      "kids\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  24\n",
      "_______________\n",
      "lovers\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  25\n",
      "_______________\n",
      "displays\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  26\n",
      "_______________\n",
      "warrior-angels\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  27\n",
      "_______________\n",
      "collection\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  28\n",
      "_______________\n",
      "collection\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  29\n",
      "_______________\n",
      "paintings\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  30\n",
      "_______________\n",
      "collection\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  31\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "which\n",
      "Prado\n",
      "Prado\n",
      "here\n",
      "Prado\n",
      "\n",
      "annex\n",
      "Prado\n",
      "Museo del Prado\n",
      "Prado\n",
      "Prado\n",
      "Prado\n",
      "Prado\n",
      "Casón del Buen Retiro\n",
      "Prado\n",
      "Prado\n",
      "\n",
      " the Places above correspond to the Node with number:  0\n",
      "_______________\n",
      "city\n",
      "Madrid\n",
      "Madrid\n",
      "Madrid\n",
      "\n",
      " the Places above correspond to the Node with number:  3\n",
      "_______________\n",
      "Spain\n",
      "Spain\n",
      "\n",
      " the Places above correspond to the Node with number:  4\n",
      "_______________\n",
      "Italy\n",
      "Italy\n",
      "\n",
      " the Places above correspond to the Node with number:  5\n",
      "_______________\n",
      "palace\n",
      "Palacio de Villahermosa\n",
      "\n",
      " the Places above correspond to the Node with number:  6\n",
      "_______________\n",
      "Hospital de San Carlos\n",
      "which\n",
      "\n",
      " the Places above correspond to the Node with number:  7\n",
      "_______________\n",
      "Centro de Arte Reina Sofía\n",
      "museum\n",
      "center\n",
      "Reina Sofía\n",
      "\n",
      " the Places above correspond to the Node with number:  8\n",
      "_______________\n",
      "station\n",
      "this\n",
      "affair\n",
      "Atocha train         station\n",
      "\n",
      " the Places above correspond to the Node with number:  9\n",
      "_______________\n",
      "workshop\n",
      "here\n",
      "Real Fábrica de Ta­pi­ces\n",
      "Royal         Tapestry Factory\n",
      "\n",
      " the Places above correspond to the Node with number:  10\n",
      "_______________\n",
      "it\n",
      "Parque del Buen Retiro\n",
      "Retiro Park\n",
      "Retiro Park\n",
      "space\n",
      "park\n",
      "\n",
      " the Places above correspond to the Node with number:  11\n",
      "_______________\n",
      "Palacio de Cristal\n",
      "Crystal Palace\n",
      "\n",
      " the Places above correspond to the Node with number:  12\n",
      "_______________\n",
      "Real Jardín Botánico\n",
      "space\n",
      "Royal Botanical Garden\n",
      "\n",
      " the Places above correspond to the Node with number:  13\n",
      "_______________\n",
      "which\n",
      "Plaza de la Independencia\n",
      "\n",
      " the Places above correspond to the Node with number:  14\n",
      "_______________\n",
      "\n",
      "\n",
      " the Places above correspond to the Node with number:  32\n",
      "_______________\n",
      "Córdoba\n",
      "\n",
      " the Places above correspond to the Node with number:  33\n",
      "_______________\n",
      "Seville\n",
      "\n",
      " the Places above correspond to the Node with number:  34\n",
      "_______________\n",
      "south\n",
      "\n",
      " the Places above correspond to the Node with number:  35\n",
      "_______________\n",
      "c/ Fuenterrabía, 2\n",
      "\n",
      " the Places above correspond to the Node with number:  36\n",
      "_______________\n",
      "lawns\n",
      "\n",
      " the Places above correspond to the Node with number:  37\n",
      "_______________\n",
      "gardens\n",
      "\n",
      " the Places above correspond to the Node with number:  38\n",
      "_______________\n",
      "place\n",
      "\n",
      " the Places above correspond to the Node with number:  39\n",
      "_______________\n",
      "lake\n",
      "\n",
      " the Places above correspond to the Node with number:  40\n",
      "_______________\n",
      "center\n",
      "\n",
      " the Places above correspond to the Node with number:  41\n",
      "_______________\n",
      "solarium\n",
      "\n",
      " the Places above correspond to the Node with number:  42\n",
      "_______________\n",
      "corner\n",
      "\n",
      " the Places above correspond to the Node with number:  43\n",
      "_______________\n",
      "barrios\n",
      "\n",
      " the Places above correspond to the Node with number:  44\n",
      "_______________\n",
      "Zaragoza\n",
      "\n",
      " the Places above correspond to the Node with number:  45\n",
      "_______________\n",
      "scene\n",
      "\n",
      " the Places above correspond to the Node with number:  46\n",
      "_______________\n",
      "rooms\n",
      "\n",
      " the Places above correspond to the Node with number:  47\n",
      "_______________\n",
      "floor\n",
      "\n",
      " the Places above correspond to the Node with number:  48\n",
      "_______________\n",
      "floor\n",
      "\n",
      " the Places above correspond to the Node with number:  49\n",
      "_______________\n",
      "Crete\n",
      "\n",
      " the Places above correspond to the Node with number:  50\n",
      "_______________\n",
      "Toledo\n",
      "\n",
      " the Places above correspond to the Node with number:  51\n",
      "_______________\n",
      "Paris\n",
      "\n",
      " the Places above correspond to the Node with number:  52\n",
      "_______________\n",
      "Venice\n",
      "\n",
      " the Places above correspond to the Node with number:  53\n",
      "_______________\n",
      "rooms\n",
      "\n",
      " the Places above correspond to the Node with number:  54\n",
      "_______________\n",
      "hill\n",
      "\n",
      " the Places above correspond to the Node with number:  55\n",
      "_______________\n",
      "Museo         Thyssen-Bor­nemizsa\n",
      "\n",
      " the Places above correspond to the Node with number:  56\n",
      "_______________\n",
      "anchor\n",
      "\n",
      " the Places above correspond to the Node with number:  57\n",
      "_______________\n",
      "trio\n",
      "\n",
      " the Places above correspond to the Node with number:  58\n",
      "_______________\n",
      "landmark\n",
      "\n",
      " the Places above correspond to the Node with number:  59\n",
      "_______________\n",
      "old         Madrid\n",
      "\n",
      " the Places above correspond to the Node with number:  60\n",
      "_______________\n",
      "c/ Santa I­sa­bel 52\n",
      "\n",
      " the Places above correspond to the Node with number:  61\n",
      "_______________\n",
      "Museum of Modern Art\n",
      "\n",
      " the Places above correspond to the Node with number:  62\n",
      "_______________\n",
      "New York\n",
      "\n",
      " the Places above correspond to the Node with number:  63\n",
      "_______________\n",
      "garden\n",
      "\n",
      " the Places above correspond to the Node with number:  64\n",
      "_______________\n",
      "Elsewhere\n",
      "\n",
      " the Places above correspond to the Node with number:  65\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "QSLINKS:\n",
      "\n",
      "node  15 is connected by QSLink to  0 with relType NTPP\n",
      "node  22 is connected by QSLink to  65 with relType IN\n",
      "node  23 is connected by QSLink to  65 with relType IN\n",
      "node  47 is connected by QSLink to  0 with relType IN\n",
      "node  18 is connected by QSLink to  0 with relType IN\n",
      "node  19 is connected by QSLink to  0 with relType IN\n",
      "node  28 is connected by QSLink to  0 with relType NTPP\n",
      "node  29 is connected by QSLink to  0 with relType NTPP\n",
      "node  20 is connected by QSLink to  6 with relType IN\n",
      "node  59 is connected by QSLink to  60 with relType IN\n",
      "node  8 is connected by QSLink to  7 with relType EQ\n",
      "node  62 is connected by QSLink to  63 with relType IN\n",
      "node  30 is connected by QSLink to  8 with relType NTPP\n",
      "node  64 is connected by QSLink to  9 with relType NTPP\n",
      "node  7 is connected by QSLink to  61 with relType IN\n",
      "node  10 is connected by QSLink to  36 with relType IN\n",
      "node  37 is connected by QSLink to  11 with relType IN\n",
      "node  38 is connected by QSLink to  11 with relType IN\n",
      "node  40 is connected by QSLink to  41 with relType IN\n",
      "node  41 is connected by QSLink to  11 with relType NTPP\n",
      "node  13 is connected by QSLink to  0 with relType EC\n",
      "node  26 is connected by QSLink to  13 with relType IN\n",
      "node  21 is connected by QSLink to  43 with relType TPP\n",
      "node  43 is connected by QSLink to  11 with relType TPP\n",
      "node  27 is connected by QSLink to  21 with relType EC\n",
      "\n",
      " \n",
      " OLINKS:\n",
      "\n",
      "node  0 is connected by OLink to  55 with relType UP\n",
      "node  10 is connected by OLink to  9 with relType SOUTHEAST\n",
      "node  11 is connected by OLink to  0 with relType EAST\n",
      "node  13 is connected by OLink to  0 with relType BESIDE\n",
      "node  27 is connected by OLink to  21 with relType ABOVE\n",
      "node  44 is connected by OLink to  14 with relType EAST\n"
     ]
    }
   ],
   "source": [
    "print('I have tried in latex with Tikz, with paint, \\n with Xournal and even simply with colors in python, still i could not make it look somehow ok\\n but it was awfull and with many mistakes. Therefore, here you can see a description of the graph: \\n all the nodes with their types and all the connections between them')\n",
    "print('\\n Prado_museum graph: ')\n",
    "gr(xml1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here the same problem. But we also have many recognized entities and places, which are not any of both classes\n",
      " you can see it e.g. in a node number 1.\n",
      "\n",
      " Bicycles: \n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "Bicitekas\n",
      "I\n",
      "I\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  1\n",
      "_______________\n",
      "cars\n",
      "they\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  6\n",
      "_______________\n",
      "people\n",
      "they\n",
      "they\n",
      "them\n",
      "cyclist\n",
      "they\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  8\n",
      "_______________\n",
      "army\n",
      "Hernan Cortez\n",
      "\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  10\n",
      "_______________\n",
      "they\n",
      "others\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  11\n",
      "_______________\n",
      "vehicle\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  12\n",
      "_______________\n",
      "cars\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  13\n",
      "_______________\n",
      "light\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  14\n",
      "_______________\n",
      "buses\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  15\n",
      "_______________\n",
      "taxis\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  16\n",
      "_______________\n",
      "team\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  17\n",
      "_______________\n",
      "cloud\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  18\n",
      "_______________\n",
      "cyclists\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  19\n",
      "_______________\n",
      "man\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  20\n",
      "_______________\n",
      "man\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  21\n",
      "_______________\n",
      "infrastructure\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  22\n",
      "_______________\n",
      "woman\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  23\n",
      "_______________\n",
      "descendents\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  24\n",
      "_______________\n",
      "civilization\n",
      "\n",
      " the Spatial Entities above correspond to the Node with number:  25\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "valley\n",
      "\n",
      " the Places above correspond to the Node with number:  3\n",
      "_______________\n",
      "Mexico City\n",
      "city\n",
      "town\n",
      "city\n",
      "city\n",
      "city\n",
      "city\n",
      "Mexico City\n",
      "Mexico City\n",
      "area\n",
      "Mexico City\n",
      "city\n",
      "Mexico City\n",
      "city\n",
      "Mexico city\n",
      "city\n",
      "city\n",
      "Mexico City\n",
      "city\n",
      "\n",
      " the Places above correspond to the Node with number:  4\n",
      "_______________\n",
      "Logos middle school\n",
      "school\n",
      "\n",
      " the Places above correspond to the Node with number:  5\n",
      "_______________\n",
      "ruins\n",
      "lake\n",
      "lake\n",
      "\n",
      "\n",
      " the Places above correspond to the Node with number:  7\n",
      "_______________\n",
      "Iztacihuatl\n",
      "Popocatepetl\n",
      "\n",
      "volcanoes\n",
      "\n",
      " the Places above correspond to the Node with number:  9\n",
      "_______________\n",
      "\n",
      "\n",
      " the Places above correspond to the Node with number:  26\n",
      "_______________\n",
      "\n",
      "\n",
      " the Places above correspond to the Node with number:  27\n",
      "_______________\n",
      "\n",
      "\n",
      " the Places above correspond to the Node with number:  28\n",
      "_______________\n",
      "organization\n",
      "\n",
      " the Places above correspond to the Node with number:  29\n",
      "_______________\n",
      "town\n",
      "\n",
      " the Places above correspond to the Node with number:  30\n",
      "_______________\n",
      "National Institute of Ecology\n",
      "\n",
      " the Places above correspond to the Node with number:  31\n",
      "_______________\n",
      "Mexico\n",
      "\n",
      " the Places above correspond to the Node with number:  32\n",
      "_______________\n",
      "U.S.\n",
      "\n",
      " the Places above correspond to the Node with number:  33\n",
      "_______________\n",
      "institute\n",
      "\n",
      " the Places above correspond to the Node with number:  34\n",
      "_______________\n",
      "shacks\n",
      "\n",
      " the Places above correspond to the Node with number:  35\n",
      "_______________\n",
      "Venezuela\n",
      "\n",
      " the Places above correspond to the Node with number:  36\n",
      "_______________\n",
      "homes\n",
      "\n",
      " the Places above correspond to the Node with number:  37\n",
      "_______________\n",
      "ruins\n",
      "\n",
      " the Places above correspond to the Node with number:  38\n",
      "_______________\n",
      "temple\n",
      "\n",
      " the Places above correspond to the Node with number:  39\n",
      "_______________\n",
      "museum\n",
      "\n",
      " the Places above correspond to the Node with number:  40\n",
      "_______________\n",
      "pyramids\n",
      "\n",
      " the Places above correspond to the Node with number:  41\n",
      "_______________\n",
      "Teotihuacan\n",
      "\n",
      " the Places above correspond to the Node with number:  42\n",
      "_______________\n",
      "here\n",
      "\n",
      " the Places above correspond to the Node with number:  43\n",
      "_______________\n",
      "capital\n",
      "\n",
      " the Places above correspond to the Node with number:  44\n",
      "_______________\n",
      "place\n",
      "\n",
      " the Places above correspond to the Node with number:  45\n",
      "_______________\n",
      "Los Angeles\n",
      "\n",
      " the Places above correspond to the Node with number:  46\n",
      "_______________\n",
      "\n",
      "\n",
      " the Places above correspond to the Node with number:  47\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "QSLINKS:\n",
      "\n",
      "node  22 is connected by QSLink to  30 with relType IN\n",
      "node  41 is connected by QSLink to  42 with relType IN\n",
      "node  43 is connected by QSLink to  4 with relType IN\n",
      "node  47 is connected by QSLink to  9 with relType EC\n",
      "node  47 is connected by QSLink to  9 with relType EC\n",
      "node  26 is connected by QSLink to  47 with relType EC\n",
      "node  27 is connected by QSLink to  47 with relType EC\n",
      "\n",
      " \n",
      " OLINKS:\n",
      "\n",
      "node  9 is connected by OLink to  47 with relType ACROSS\n",
      "node  26 is connected by OLink to  47 with relType ACROSS\n"
     ]
    }
   ],
   "source": [
    "print('here the same problem. But we also have many recognized entities and places, which are not any of both classes\\n you can see it e.g. in a node number 1.')\n",
    "print('\\n Bicycles: ')\n",
    "gr(xml2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here you can see that sentences may also be false detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dd= nlp(data[729:1000])\n",
    "data[729:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in dd.sents:\n",
    "    print([token for token in sent])\n",
    "    print('___')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I've tried to handle it, but with no success.\n",
    "\n",
    "'\\n' with 5,6,8 or 10 Blankspaces are initialy a sentence start (if you hadn't change anything in the package earlier), so I've changed it. So that in the following sentence you can see, that 'the problem is solved'. But for our text it doesn't work, and I don't know why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"sentence begins\\n     sentence ends.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "print(\"Before:\", [sent.text for sent in doc.sents])\n",
    "\n",
    "#Output: Before: ['sentence begins\\n     ', 'sentence ends.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_boundaries(doc):\n",
    "    '''\n",
    "    It seems to be crucial for the correct sentence tokenization of the 'Asaki text'\n",
    "    All the '\\n          ', '\\n     ', etc. are not prefectly structured: has different number \n",
    "    of white spaces and therefore may be seen as a sentence ending\n",
    "    \n",
    "    '''\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == '\\n     ' or token.text == '\\n      ' or token.text == '\\n          ' or token.text == '\\n        ':\n",
    "            doc[token.i+1].is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(set_custom_boundaries, before=\"parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
